\section*{ABSTRACT}
\vspace{0.5cm}
% EXAMPLE
Autonomous mobile robots are vital in areas such as logistics and healthcare, where they rely on complex navigation systems to effectively manoeuvre in dynamic indoor environments. Conventional 2D LiDAR systems, while favourable for obstacle detection in a single plane. However, they perform poorly in recognising low-lying and complex obstacles, limiting their operational efficiency and safety.
This project proposes a novel sensor fusion method that combines the 2D breadth of LiDAR with the stereo vision data from a depth camera. By converting depth camera outputs into LiDAR messages, the robot-accessible environmental data is enriched, resulting in significantly enhanced obstacle detection in multiple dimensions. This fusion technique significantly closes the gap in 2D LiDAR obstacle detection capabilities.
This sensor fusion algorithm's is implemented based on enhancements to existing algorithms in the ROS2 framework, simulated and evaluated in Gazebo and RViz2. The enhanced algorithm was combined with the fusion algorithm of this project to consider and improve the problems that can arise when multiple fusions are performed.
The results show a significant improvement in the robot's ability to detect and bypass direct and low-lying obstacles.
\vspace{0.5cm}

\textbf{Keywords:} Mobile Robot, Depth Camera, Laser Scan, 2D Mapping, Localisation, Mapping, Navigation

\vspace{0.5cm}
\textbf{NOMENCLATURE}
\\
$\alpha \quad$ alpha